{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0479a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/galogonzalvo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/galogonzalvo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ddfefa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>FILE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...</td>\n",
       "      <td>00249.5f45607c1bffe89f60ba1ec9f878039a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ATTENTION: This is a MUST for ALL Computer Use...</td>\n",
       "      <td>00373.ebe8670ac56b04125c25100a36ab0510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a multi-part message in MIME format.\\n...</td>\n",
       "      <td>00214.1367039e50dc6b7adb0f2aa8aba83216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...</td>\n",
       "      <td>00210.050ffd105bd4e006771ee63cabc59978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the bottom line.  If you can GIVE AWAY...</td>\n",
       "      <td>00033.9babb58d9298daa2963d4f514193d7d6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CATEGORY                                            MESSAGE  \\\n",
       "0         1  Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...   \n",
       "1         1  ATTENTION: This is a MUST for ALL Computer Use...   \n",
       "2         1  This is a multi-part message in MIME format.\\n...   \n",
       "3         1  IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...   \n",
       "4         1  This is the bottom line.  If you can GIVE AWAY...   \n",
       "\n",
       "                                FILE_NAME  \n",
       "0  00249.5f45607c1bffe89f60ba1ec9f878039a  \n",
       "1  00373.ebe8670ac56b04125c25100a36ab0510  \n",
       "2  00214.1367039e50dc6b7adb0f2aa8aba83216  \n",
       "3  00210.050ffd105bd4e006771ee63cabc59978  \n",
       "4  00033.9babb58d9298daa2963d4f514193d7d6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Spam Email raw text for NLP.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147ebaaa",
   "metadata": {},
   "source": [
    "**category** is the label, 1 is spam, 0 is good mail\n",
    "\n",
    "**message** is the body of the message\n",
    "\n",
    "**file_name** is an unique identifier of every file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893a071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3900\n",
       "1    1896\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be8bf474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " 'GGggGG',\n",
       " 'feet',\n",
       " 'it',\n",
       " 'going',\n",
       " 'HTML',\n",
       " 'bads',\n",
       " 'bads',\n",
       " 'randoms',\n",
       " 'badly']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "test_message = 'Hey,, GGggGG feet it going? <HTML><bads> bads \"randoms\" badly'\n",
    "\n",
    "test_message_tokenized = tokenizer.tokenize(test_message) #keeps the important part of the message\n",
    "test_message_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d113d844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'gggggg',\n",
       " 'feet',\n",
       " 'it',\n",
       " 'going',\n",
       " 'html',\n",
       " 'bads',\n",
       " 'bads',\n",
       " 'randoms',\n",
       " 'badly']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_message_lowercased = [t.lower() for t in test_message_tokenized] #make lowercase\n",
    "test_message_lowercased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d74dea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0acb17ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'gggggg',\n",
       " 'foot',\n",
       " 'it',\n",
       " 'going',\n",
       " 'html',\n",
       " 'bad',\n",
       " 'bad',\n",
       " 'randoms',\n",
       " 'badly']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is very similar. What it does is to extract meaning of the previous form\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "test_message_lemmatized_tokens = [lemmatizer.lemmatize(t) for t in test_message_lowercased]\n",
    "test_message_lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a94b3dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'gggggg', 'foot', 'going', 'html', 'bad', 'bad', 'randoms', 'badly']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english') #Eliminates stop words (useless words)\n",
    "\n",
    "test_message_useful_tokens = [t for t in test_message_lemmatized_tokens if t not in stopwords]\n",
    "test_message_useful_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da950c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'gggggg', 'foot', 'going', 'html', 'bad', 'bad', 'randoms', 'badly']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def message_to_token_list(s):\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    lowercased_tokens = [t.lower() for t in tokens]\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(t) for t in lowercased_tokens]\n",
    "    useful_tokens = [t for t in lemmatized_tokens if t not in stopwords]\n",
    "    \n",
    "    return useful_tokens\n",
    "\n",
    "message_to_token_list(test_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c1a27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>FILE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\n&lt;HTML&gt;&lt;FONT  BACK=\"#ffffff\" style=\"BACKGRO...</td>\n",
       "      <td>00118.141d803810acd9d4fc23db103dddfcd9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;html&gt;&lt;body bgColor=\"#CCCCCC\" topmargin=1 onMo...</td>\n",
       "      <td>00463.0bc4e08af0529dd773d9f10f922547db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Quoting Paul Linehan (plinehan@yahoo.com):\\n\\n...</td>\n",
       "      <td>00358.87ee38040ac1f42320c7b89628b1850a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=http://www.aaronsw.com/weblog/&gt;\\n\\nAar...</td>\n",
       "      <td>01274.0d083a2d3b30061efdc2cc73ee9e76e3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Oh yeah, the link for more info:\\n\\n\\n\\nhttp:/...</td>\n",
       "      <td>00756.2b2ec73ad20a4e0bdf31632ac019233b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CATEGORY                                            MESSAGE  \\\n",
       "0         1  \\n\\n<HTML><FONT  BACK=\"#ffffff\" style=\"BACKGRO...   \n",
       "1         1  <html><body bgColor=\"#CCCCCC\" topmargin=1 onMo...   \n",
       "2         0  Quoting Paul Linehan (plinehan@yahoo.com):\\n\\n...   \n",
       "3         0  <a href=http://www.aaronsw.com/weblog/>\\n\\nAar...   \n",
       "4         0  Oh yeah, the link for more info:\\n\\n\\n\\nhttp:/...   \n",
       "\n",
       "                                FILE_NAME  \n",
       "0  00118.141d803810acd9d4fc23db103dddfcd9  \n",
       "1  00463.0bc4e08af0529dd773d9f10f922547db  \n",
       "2  00358.87ee38040ac1f42320c7b89628b1850a  \n",
       "3  01274.0d083a2d3b30061efdc2cc73ee9e76e3  \n",
       "4  00756.2b2ec73ad20a4e0bdf31632ac019233b  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and test sample\n",
    "df = df.sample(frac=1,random_state=1) # Mix the dataset\n",
    "df = df.reset_index(drop=True) #If drop is set to false (default) the previous index is added as a new column\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5afba7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      CATEGORY                                            MESSAGE  \\\n",
       " 0            1  \\n\\n<HTML><FONT  BACK=\"#ffffff\" style=\"BACKGRO...   \n",
       " 1            1  <html><body bgColor=\"#CCCCCC\" topmargin=1 onMo...   \n",
       " 2            0  Quoting Paul Linehan (plinehan@yahoo.com):\\n\\n...   \n",
       " 3            0  <a href=http://www.aaronsw.com/weblog/>\\n\\nAar...   \n",
       " 4            0  Oh yeah, the link for more info:\\n\\n\\n\\nhttp:/...   \n",
       " ...        ...                                                ...   \n",
       " 4631         0  Gregory Alan Bolcer:\\n\\n>I'm not sure since I ...   \n",
       " 4632         1  New Account For: zzzz@spamassassin.taint.org\\n...   \n",
       " 4633         0  >>>>> \"O\" == Owen Byrne <owen@permafrost.net> ...   \n",
       " 4634         0  This is an automated response to a message you...   \n",
       " 4635         0  http://www.ouchytheclown.com/welcome.html\\n\\n\\...   \n",
       " \n",
       "                                    FILE_NAME  \n",
       " 0     00118.141d803810acd9d4fc23db103dddfcd9  \n",
       " 1     00463.0bc4e08af0529dd773d9f10f922547db  \n",
       " 2     00358.87ee38040ac1f42320c7b89628b1850a  \n",
       " 3     01274.0d083a2d3b30061efdc2cc73ee9e76e3  \n",
       " 4     00756.2b2ec73ad20a4e0bdf31632ac019233b  \n",
       " ...                                      ...  \n",
       " 4631  00830.3a2cadbd29e654a7cbbf64ba4bdc378d  \n",
       " 4632  00354.dca4b8984863a76ffd01a33888498288  \n",
       " 4633  00346.f1d941485f6a20b29329111c59760585  \n",
       " 4634  00033.2ceb520d2c6500ccf24357f2ebdce618  \n",
       " 4635  00170.14c40e625814c14dfe2eb997157c6437  \n",
       " \n",
       " [4636 rows x 3 columns],\n",
       "       CATEGORY                                            MESSAGE  \\\n",
       " 0            0  This is just an semi-educated guess - if I'm w...   \n",
       " 1            1  ------=_NextPart_000_00B0_58C75D0E.A4523D08\\n\\...   \n",
       " 2            0  I seem to be getting the known spam message nu...   \n",
       " 3            0  \\n\\n\\n\\n>>>>> On Mon, 30 Sep 2002, \"Ted\" == Te...   \n",
       " 4            1  This is a multi-part message in MIME format.\\n...   \n",
       " ...        ...                                                ...   \n",
       " 1155         1  <html>\\n\\n\\n\\n<body>\\n\\n\\n\\n<font size=\"2\" PTS...   \n",
       " 1156         0  \\n\\n\\n\\nformail did the trick. Thanks to those...   \n",
       " 1157         0  URL: http://www.askbjoernhansen.com/archives/2...   \n",
       " 1158         1  <html>\\n\\n<head>\\n\\n   <meta http-equiv=3D\"Con...   \n",
       " 1159         0  >>>>> \"E\" == Elias Sinderson <elias@cse.ucsc.e...   \n",
       " \n",
       "                                    FILE_NAME  \n",
       " 0     01503.5e13994a5676296ed31b14e83367031c  \n",
       " 1     00441.3b9c3055e08bda4c0f7eea43749e324c  \n",
       " 2     00623.8bf6da05b986d3b16c208102e1c266f2  \n",
       " 3     01143.77077715a838bb473dad6a466d2e2403  \n",
       " 4     00224.1b3430b101a8a8b22493c4948fcbe9cc  \n",
       " ...                                      ...  \n",
       " 1155  00552.877d8dbff829787aa8349b433a8421f0  \n",
       " 1156  00647.97e77e8264c32c8b05077edc15721ba2  \n",
       " 1157  02055.80f7eff41824e0337e453a988ceda994  \n",
       " 1158  00376.f4ed5f002f9b6b320a67f1da9cacbe72  \n",
       " 1159  00987.1d700056f6a043acd5d388ca81fa0b1f  \n",
       " \n",
       " [1160 rows x 3 columns])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_index = int(len(df)*0.8) \n",
    "train_df, test_df = df[:split_index], df[split_index:]\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d074b78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86415"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counter = {}\n",
    "\n",
    "for message in train_df['MESSAGE']:\n",
    "    message_as_token_lst = message_to_token_list(message)\n",
    "    \n",
    "    for token in message_as_token_lst:\n",
    "        if token in token_counter:\n",
    "            token_counter[token] +=1\n",
    "        else:\n",
    "            token_counter[token] =1\n",
    "len(token_counter) #length of unique words in messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc0f097c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3d', 'b', 'br', 'com', 'font', 'http', 'p', 'size', 'td', 'tr'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just keep words which appear many times\n",
    "\n",
    "def keep_token(processed_token,threshold):\n",
    "    if processed_token not in token_counter:\n",
    "        return False\n",
    "    else:\n",
    "        return token_counter[processed_token] > threshold\n",
    "    \n",
    "features = set()\n",
    "for token in token_counter:\n",
    "    if keep_token(token,10000):\n",
    "        features.add(token)\n",
    "        \n",
    "#This are the most popular words. Assume we can use them to distinguish fake and true mails\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61cf2136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'com': 0,\n",
       " 'tr': 1,\n",
       " 'br': 2,\n",
       " 'td': 3,\n",
       " 'b': 4,\n",
       " 'size': 5,\n",
       " 'font': 6,\n",
       " 'http': 7,\n",
       " 'p': 8,\n",
       " '3d': 9}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(features)\n",
    "\n",
    "token_to_index_mapping = {t:i for t,i in zip(features,range(len(features)))}\n",
    "token_to_index_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f898798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['com', 'tr', 'br', 'td', 'b', 'size', 'font', 'http', 'p', '3d']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0dc5692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 1., 0., 1., 0., 2., 0., 0., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Produce sparse vector: bag of words, based on our main words\n",
    "import numpy as np\n",
    "\n",
    "def message_to_count_vector(message):\n",
    "    count_vector = np.zeros(len(features))\n",
    "    \n",
    "    processed_list_of_tokens = message_to_token_list(message)\n",
    "    \n",
    "    for token in processed_list_of_tokens:\n",
    "        if token not in features:\n",
    "            continue\n",
    "        index = token_to_index_mapping[token]\n",
    "        count_vector[index] += 1\n",
    "    return count_vector\n",
    "\n",
    "message_to_count_vector('3d b <br> .com bad font font com randoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05eb57d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.,  0., 33.,  0.,  2.,  2.,  4.,  6.,  0.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_to_count_vector(train_df['MESSAGE'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8fc8ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY                                                     1\n",
       "MESSAGE      \\n\\n<HTML><FONT  BACK=\"#ffffff\" style=\"BACKGRO...\n",
       "FILE_NAME               00118.141d803810acd9d4fc23db103dddfcd9\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebde304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y(dff):\n",
    "    y = dff['CATEGORY'].to_numpy().astype(int)\n",
    "    \n",
    "    message_col = dff['MESSAGE']\n",
    "    count_vectors = []\n",
    "    \n",
    "    for message in message_col:\n",
    "        count_vector = message_to_count_vector(message)\n",
    "        count_vectors.append(count_vector)\n",
    "        \n",
    "    X = np.array(count_vectors).astype(int)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f24793d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_to_X_y(train_df)\n",
    "\n",
    "X_test, y_test = df_to_X_y(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf8778ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform input array so that all numbers are much closer to 0\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f290902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86       788\n",
      "           1       0.99      0.32      0.48       372\n",
      "\n",
      "    accuracy                           0.78      1160\n",
      "   macro avg       0.87      0.66      0.67      1160\n",
      "weighted avg       0.83      0.78      0.74      1160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Use logistic regression model and build classification report\n",
    "lr = LogisticRegression().fit(X_train,y_train)\n",
    "print(classification_report(y_test,lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b31f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       788\n",
      "           1       0.91      0.57      0.70       372\n",
      "\n",
      "    accuracy                           0.84      1160\n",
      "   macro avg       0.87      0.77      0.80      1160\n",
      "weighted avg       0.85      0.84      0.83      1160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare logistic regression to random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train,y_train)\n",
    "print(classification_report(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464122c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
